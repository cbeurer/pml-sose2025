\documentclass[a4paper]{article}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage{blindtext} % Package to generate dummy text
\usepackage{charter} % Use the Charter font
\usepackage[utf8]{inputenc} % Use UTF-8 encoding
\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\usepackage{microtype} % Slightly tweak font spacing for aesthetics
\usepackage{amsthm, amsmath, amssymb} % Mathematical typesetting
\usepackage{float} % Improved interface for floating objects
\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{graphicx, multicol} % Enhanced support for graphics
\usepackage{xcolor} % Driver-independent color extensions
\usepackage{pseudocode} % Environment for specifying algorithms in a natural way
\usepackage{datetime} % Uses YEAR-MONTH-DAY format for dates

\addtolength{\hoffset}{-2.25cm}
\addtolength{\textwidth}{4.5cm}
\addtolength{\voffset}{-3.25cm}
\addtolength{\textheight}{5cm}

\setlength{\parskip}{1ex}
\setlength{\parindent}{0in}

\DeclareUnicodeCharacter{03B1}{$\alpha$}

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{}\renewcommand{\headrulewidth}{0pt} % Blank out the default header
\fancyfoot[L]{} % Custom footer text
\fancyfoot[C]{} % Custom footer text
\fancyfoot[R]{\thepage} % Custom footer text
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}

% define new commands
\newcommand{\Real}{{\mathbb R}}
\newcommand{\Normal}[3]{{\mathcal N} \left({#1};{#2},{#3}\right)}
\newcommand{\Gauss}[3]{{\mathcal G} \left({#1};{#2},{#3}\right)}
\newcommand{\NormalStandard}[1]{{\mathcal N} \left({#1}\right)}
\newcommand{\GaussStandard}[1]{{\mathcal G} \left({#1}\right)}
\newcommand{\NormalCDF}[3]{\Phi \left({#1};{#2},{#3}\right)}
\newcommand{\NormalStandardCDF}[1]{\Phi \left({#1}\right)}
\newcommand{\NormalMoment}[3]{M_{#1} \left({#2},{#3}\right)}
\newcommand{\WeightedEmpirical}[3]{{\mathcal E} \left({#1};{#2},{#3}\right)}
\newcommand{\Empirical}[2]{{\mathcal E} \left({#1}; {#2}\right)}
\newcommand{\Bernoulli}[2]{{\mathrm{Ber}} \left({#1};{#2}\right)}
\newcommand{\Ber}[2]{{\mathcal B} \left({#1};{#2}\right)}
\newcommand{\expect}[1]{{\mathbb E \left[ {#1} \right]}}
\newcommand{\var}[1]{{\mathbb V \left[ {#1} \right]}}
\newcommand{\dirac}[1]{{\delta \left( {#1} \right)}}
\newcommand{\uniform}[1]{{\mathcal U} \left( {#1} \right)}
\newcommand{\identity}[1]{{{\mathbb{I}} \left( {#1} \right)}}
\newcommand{\incoming}[1]{\widecheck{#1}}
\newcommand{\outgoing}[1]{\widehat{#1}}
\newcommand{\intd}[1]{\ \mathrm{d}{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
% \newcommand{\incoming}[1]{\stackrel{\rightarrow}{#1}}
% \newcommand{\outgoing}[1]{\stackrel{\leftarrow}{#1}}
\newcommand{\neighbours}[1]{{\mathrm{ne} \left( {#1} \right)}}


% define new environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

%----------------------------------------------------------------------------------------

\begin{document}

%-------------------------------
%	TITLE SECTION (do not modify unless you really need to)
%-------------------------------
\fancyhead[C]{}
\hrule \medskip
\begin{minipage}{0.295\textwidth}
    \raggedright
    \hfill\\
\end{minipage}
\begin{minipage}{0.4\textwidth}
    \centering
    \large
    On Normalization Constants in Message Passing\\
\end{minipage}
\begin{minipage}{0.295\textwidth}
    \raggedleft
    \hfill\\
\end{minipage}
\medskip\hrule
\bigskip
 
\section*{Factor Graphs and Message Passing}

Before we derive some useful results on efficient and distributed algorithms for computing the normalization constant in message passing, we would like to introduce the concept of factor graphs and message passing. A factor graph is a bipartite graph that represents the factorization of a function of $n$ variables. In a factor graph, we have two types of nodes: {\em variable nodes} (denoted by $X_1,\ldots,X_n$) and {\em factor nodes} (denoted by $f_1,\ldots,f_m$). Variable nodes represent random variables, while factor nodes represent functions that depend on the variables. More formally, a factor graph defines the non-normalized joint probability function 
\begin{align}
    p(x_1,\ldots,x_n) = \prod_{i=1}^m f_i(\bs{x}_{\neighbours{f_i}}) \,, \label{eq:joint}
\end{align}
where $\neighbours{f_i} \subseteq \{1,\ldots,n\}$ denotes the index set of variables that are connected to the factor node $f_i$, $\bs{x}_{\neighbours{f_i}}$ is list of values $x_j$ where $j \in \neighbours{f_i}$. Moreover, $\neighbours{X_j} \subseteq \{1,\ldots,m\}$ denotes the set of factors $f_i$ that are connected to the variable node $X_j$.

\paragraph{Marginals and Message Passing} In message passing, we are interested to compute the non-normalized marginal $p_{X_j}(x_j)$ defined by
\begin{align}
    p_{X_j}(x_j) = \sum_{\{x_1\}}\cdots\sum_{\{x_{j-1}\}}\sum_{\{x_{j+1}\}}\cdots\sum_{\{x_n\}} p(x_1,\ldots,x_n) \label{eq:marginal_def}
\end{align}
If the factor graph is a tree, then we can easily compute $p_{X_j}(x_j)$ by recursively applying the distributive law
\begin{align}
    p_{X_j} (x_j) &= \prod_{i \in \neighbours{X_j}} m_{f_i \to X_j}(x_j) \,, \label{eq:marginal} \\
    m_{f_i \to X_j}(x_j) &= \sum_{\{\bs{x}_{\neighbours{f_i} \setminus \{j\}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i} \setminus \{j\}} m_{X_k \to f_i}(x_k) \right] \,, \label{eq:factor_to_var} \\
    m_{X_j \to f_i}(x_j) &= \prod_{k \in \neighbours{X_j} \setminus \{i\}} m_{f_k \to X_j}(x_j) \,, \label{eq:var_to_factor}
\end{align}
Note that by virtue of \eqref{eq:marginal} and \eqref{eq:var_to_factor} we have for any $f_i$ and $X_j, j\in \neighbours{f_i}$, 
\begin{align}
    p_{X_j}(x_j) = m_{f_i \to X_j}(x_j) \cdot m_{X_j \to f_i}(x_j)\,. \label{eq:marginal_factor}
\end{align}

\paragraph{Normalization constant} Often, we require a normalized joint probability $\widetilde{p}(x_1,\ldots,x_n) = \frac{1}{Z} \cdot p(x_1,\ldots,x_n)$ rather than a non-normalized joint probability $p(x_1,\ldots,x_n)$ where the normalization constant $Z$ defined by
\begin{align}
    Z = \sum_{\{x_1\}} \cdots \sum_{\{x_n\}} p(x_1,\ldots,x_n) = \sum_{\{x_1\}} \cdots \sum_{\{x_n\}} \prod_{i=1}^m f_i(\bs{x}_{\neighbours{f_i}}) \,. \label{eq:partition}
\end{align}
Note that by definition for any variable $X_j$, the normalization is also obtained from \eqref{eq:marginal_def} by summing over all values of $X_j$. Thus, for every variable $X_j$ the normalization constant is also given by
\begin{align}
    Z = \sum_{\{x_j\}} p_{X_j}(x_j) \,. \label{eq:partition_marginal}
\end{align}
Looking at \eqref{eq:marginal_factor} and \eqref{eq:factor_to_var}, we see that \eqref{eq:partition_marginal} can also be written as
\begin{align}
    Z = \sum_{\{x_j\}} m_{f_i \to X_j}(x_j) \cdot m_{X_j \to f_i}(x_j) = \sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i}} m_{X_k \to f_i}(x_k) \right] \,, \label{eq:partition_factor}
\end{align}
where we used \eqref{eq:factor_to_var} for $m_{f_i \to X_j}(x_j)$. In graph language, \eqref{eq:partition_marginal} follows from making the variable node $X_j$ the root of the factor tree and \eqref{eq:partition_factor} follows from making the factor node $f_i$ the root of the factor tree (and the summing over each of variables in the branches individually).

\section*{Normalization Constants in Message Passing}
In addition to the $n$ ways to compute the normalization constant using \eqref{eq:partition_marginal} or the $m$ ways to compute the normalization constant using \eqref{eq:partition_factor}, we can also compute the normalization constant by message passing. Here we will present a result that allows us to compute the normalization constant by message passing in a distributed manner using arbitraty normalization of the messages. Thus, for every factor $f_i$ and for every variable $X_j$, we introduce two scaled messages by virtue of 
\begin{align}
    \widetilde{m}_{f_i \to X_j}(x_j) &= \alpha_{i,j} \cdot m_{f_i \to X_j}(x_j) \,, \label{eq:factor_to_var_scaled} \\
    \widetilde{m}_{X_j \to f_i}(x_j) &= \beta_{j,i} \cdot m_{X_j \to f_i}(x_j) \,. \label{eq:var_to_factor_scaled} \,.
\end{align}

We are now in a position to state the main theorem for computing the normalization constant by message passing.
\begin{theorem}
    Given a factor tree, the normalization constant $Z$ in terms of scaled messages \eqref{eq:factor_to_var_scaled} and \eqref{eq:var_to_factor_scaled} is given by
    \begin{align}
        Z & = \left( \prod_{i=1}^m Z_{f_i} \right) \cdot \left( \prod_{j=1}^n Z_{X_j} \right)\,, \label{eq:partition_message} 
    \end{align}
    where the constants $Z_{f_i}$ for all factors $f_i$ and $Z_{X_j}$ for all variables $X_j$ are given by
    \begin{align}
        Z_{f_i} & = \frac{\sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i}} \widetilde{m}_{X_k \to f_i}(x_k) \right]}{\sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ \prod_{k \in \neighbours{f_i}} \widetilde{m}_{f_i \to X_k}(x_k) \cdot \widetilde{m}_{X_k \to f_i}(x_k) \right]} \,, \label{eq:partition_factor_message} \\
        Z_{X_j} & = \sum_{\{ x_j \}} \prod_{i \in \neighbours{X_j}} \widetilde{m}_{f_i \to X_j}(x_j) \,. \label{eq:partition_marginal_message}
    \end{align}
\end{theorem}

\begin{proof}
    We will start by simplifying \eqref{eq:partition_factor_message} in terms of the $\alpha_{i,k}, k \in \neighbours{f_i}$ and $Z$. More specifically, we see that 
    \begin{align*}
        Z_{f_i} & = \frac{\sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i}} \beta_{k,i} \cdot m_{X_k \to f_i}(x_k) \right]}{\sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ \prod_{k \in \neighbours{f_i}} \alpha_{i,k} \cdot m_{f_i \to X_k}(x_k) \cdot \beta_{k,i} \cdot m_{X_k \to f_i}(x_k) \right]} \\
        & = \frac{\left( \prod_{k \in \neighbours{f_i}} \beta_{k,i} \right) \cdot \left( \sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i}} m_{X_k \to f_i}(x_k) \right] \right)}{\left( \prod_{k \in \neighbours{f_i}} \alpha_{i,k} \right) \cdot \left( \prod_{k \in \neighbours{f_i}} \beta_{k,i} \right) \cdot \left( \sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ \prod_{k \in \neighbours{f_i}} m_{f_i \to X_k}(x_k) \cdot m_{X_k \to f_i}(x_k) \right] \right)} \\
        & = \frac{\sum_{\{\bs{x}_{\neighbours{f_i}}\}} \left[ f_i(\bs{x}_{\neighbours{f_i}}) \cdot \prod_{k \in \neighbours{f_i}} m_{X_k \to f_i}(x_k) \right]}{\left( \prod_{k \in \neighbours{f_i}} \alpha_{i,k} \right) \cdot \left( \prod_{k \in \neighbours{f_i}} \left[ \sum_{\{ x_k \}} m_{f_i \to X_k}(x_k) \cdot m_{X_k \to f_i}(x_k) \right] \right)} \\
        & = \frac{Z}{\left( \prod_{k \in \neighbours{f_i}} \alpha_{i,k} \right) \cdot Z^{\left| \neighbours{f_i} \right|}} \,,
    \end{align*}
    where we used \eqref{eq:factor_to_var_scaled} and \eqref{eq:var_to_factor_scaled} in the first line, factored out all terms $\beta_{k,i}$ and $\alpha_{k,i}$ with $k \in \neighbours{f_i}$ in the second line, swapped the summation over all $\{\bs{x}_{\neighbours{f_i}}\}$ with the product as each factor only depends on $x_k, k \in \neighbours{f_i}$ in the third line, and used \eqref{eq:partition_factor} in the numerator and \eqref{eq:partition_marginal} together with \eqref{eq:marginal_factor} in the denominator in the last line.

    Similarly, we will simplify \eqref{eq:partition_marginal_message} in terms of the $\alpha_{i,j}, i \in \neighbours{X_j}$ and $Z$ as follows:
    \begin{align*}
        Z_{X_j} & = \sum_{\{ x_j \}} \prod_{i \in \neighbours{X_j}} \alpha_{i,j} \cdot m_{f_i \to X_j}(x_j) \\
        & = \left( \prod_{i \in \neighbours{X_j}} \alpha_{i,j} \right) \cdot \left( \sum_{\{ x_j \}} \prod_{i \in \neighbours{X_j}} m_{f_i \to X_j}(x_j) \right) \\
        & = \left( \prod_{i \in \neighbours{X_j}} \alpha_{i,j} \right) \cdot Z \,,
    \end{align*}
    where we used \eqref{eq:factor_to_var_scaled} in the first line, factored out all terms $\alpha_{i,j}$ with $i \in \neighbours{X_j}$ in the second line, and used \eqref{eq:partition_marginal} together with \eqref{eq:marginal} in the last line.

    Now, putting this together we see that 
    \begin{align*}
        \left( \prod_{i=1}^m Z_{f_i} \right) \cdot \left( \prod_{j=1}^n Z_{X_j} \right) 
        & = \left( \prod_{i=1}^m \frac{Z}{\left( \prod_{k \in \neighbours{f_i}} \alpha_{i,k} \right) \cdot Z^{\left| \neighbours{f_i} \right|}} \right) \cdot \left( \prod_{j=1}^n \left( \prod_{i \in \neighbours{X_j}} \alpha_{i,j} \right) \cdot Z \right) \\
        & = \frac{Z^{n+m}}{\prod_{i=1}^m \prod_{k \in \neighbours{f_i}} Z^{\left| \neighbours{f_i} \right|}} \\
        & = \frac{Z^{n+m}}{Z^{n+m-1}} = Z \,,
    \end{align*}
    where we used the fact that 
    \begin{align*}
        \prod_{i=1}^m \prod_{k \in \neighbours{f_i}} \alpha_{i,k} = \prod_{j=1}^n \prod_{i \in \neighbours{X_j}} \alpha_{i,j} 
    \end{align*} 
    in the second line because the two products enumerate all edges of the factor graph, and used the fact that the factor graph is a tree and therefore for the total number of edges (enumerated by $\{ (i,j) | i \in \{1,\ldots,m\}, j \in \neighbours{f_i} \}$) is $n+m-1$ in the last line.
\end{proof}

\end{document}
